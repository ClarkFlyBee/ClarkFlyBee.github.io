<!DOCTYPE html>
<html lang="zh-cn" dir="auto" data-theme="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>混淆矩阵与 AUC：理解T/F/P/N分类评估指标 | ClarkFlyBee&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="
最近参与的医学场景的项目中，模型的评价指标之一是AUC。
要讲清楚这个指标，需要首先了解一个评价模型的经典工具：混淆矩阵。

混淆矩阵 —— 模型能不能“明辨是非”
基础定义
我们训练AI模型，一个典型的任务是去预测一个事情是否会发生。
那医学场景举个例子：


我们给模型输入过去手术的数据，让它学习其中的特征。


我们的目的是希望训练后的模型在接受一段时间的手术数据输入后，给出未来一定时间内发生某类异常事件的可能性。


那么如何评价这个模型做的好不好呢？简单来说，需要记录预测结果与实际情况是否一致。我们定义：


预测结果


预测为正例（Positive, P）


预测为负例（Negative, N）




实际情况


实际为正例


实际为负例




对于这四种情况排列组合，我们就会得到一个模型的混淆矩阵（Confusion Matrix）：

  
      
          
          预测为正例 P
          预测为负例 N
      
  
  
      
          实际为正例
          TP（True Positive）
          FN（False Negative）
      
      
          实际为负例
          FP（False Positive）
          TN（True Negative）
      
  

对于矩阵的四个象限，其含义分别为：

  
      
          缩写
          含义
          场景
      
  
  
      
          TP
          预测为正，实际为正
          ✅ 正确识别阳性（如：有异常事件有警报）
      
      
          TN
          预测为负，实际为负
          ✅ 正确识别阴性（如：无异常事件无警报）
      
      
          FP
          预测为正，实际为负
          ❌ 误报（如：无异常事件有警报）
      
      
          FN
          预测为负，实际为正
          ❌ 漏报（如：有异常事件无警报）
      
  


这里我经常搞糊涂，Positive和Negative分别对应的是预测的情况。预测为正例，指预测内容为事件发生，在混淆矩阵中标记为P，反之为N。
但与预测情况相对的，实际情况为正例，并不意味着对应情况记作T。
事实上，当实际情况与预测内容相匹配时，才会记为T；反之即为F。
也就是说，T 和 F 并不是标记实际情况中事件是否发生，而是表示实际情况与预测内容是否一致。

由混淆矩阵派生的关键指标
在实践中，混淆矩阵中的TP、FN、FP、TN通常是记录测试模型时，符合对应情况的测试样本数量。
比如说我们训练好了模型，测试时我们输入了1000个样本，结果分别为：


400个样本被预测为会发生异常事件

其中150个样本真的发生了异常事件，250个样本没有发生异常事件



600个样本被预测为不发生异常事件

其中50个样本真的发生了异常事件，550个样本没有发生异常事件



此时，这个模型的混淆矩阵可以记为：">
<meta name="author" content="ClarkFlyBee">
<link rel="canonical" href="https://clarkflybee.github.io/posts/2026-02-04-auc-confusion-matrix-primer/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<link rel="icon" href="https://clarkflybee.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://clarkflybee.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://clarkflybee.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://clarkflybee.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://clarkflybee.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh-cn" href="https://clarkflybee.github.io/posts/2026-02-04-auc-confusion-matrix-primer/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css" integrity="sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js" integrity="sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false}
          ],
          
          throwOnError : false
        });
    });
</script>
<meta property="og:url" content="https://clarkflybee.github.io/posts/2026-02-04-auc-confusion-matrix-primer/">
  <meta property="og:site_name" content="ClarkFlyBee&#39;s Blog">
  <meta property="og:title" content="混淆矩阵与 AUC：理解T/F/P/N分类评估指标">
  <meta property="og:description" content=" 最近参与的医学场景的项目中，模型的评价指标之一是AUC。
要讲清楚这个指标，需要首先了解一个评价模型的经典工具：混淆矩阵。
混淆矩阵 —— 模型能不能“明辨是非” 基础定义 我们训练AI模型，一个典型的任务是去预测一个事情是否会发生。
那医学场景举个例子：
我们给模型输入过去手术的数据，让它学习其中的特征。
我们的目的是希望训练后的模型在接受一段时间的手术数据输入后，给出未来一定时间内发生某类异常事件的可能性。
那么如何评价这个模型做的好不好呢？简单来说，需要记录预测结果与实际情况是否一致。我们定义：
预测结果
预测为正例（Positive, P）
预测为负例（Negative, N）
实际情况
实际为正例
实际为负例
对于这四种情况排列组合，我们就会得到一个模型的混淆矩阵（Confusion Matrix）：
预测为正例 P 预测为负例 N 实际为正例 TP（True Positive） FN（False Negative） 实际为负例 FP（False Positive） TN（True Negative） 对于矩阵的四个象限，其含义分别为：
缩写 含义 场景 TP 预测为正，实际为正 ✅ 正确识别阳性（如：有异常事件有警报） TN 预测为负，实际为负 ✅ 正确识别阴性（如：无异常事件无警报） FP 预测为正，实际为负 ❌ 误报（如：无异常事件有警报） FN 预测为负，实际为正 ❌ 漏报（如：有异常事件无警报） 这里我经常搞糊涂，Positive和Negative分别对应的是预测的情况。预测为正例，指预测内容为事件发生，在混淆矩阵中标记为P，反之为N。
但与预测情况相对的，实际情况为正例，并不意味着对应情况记作T。
事实上，当实际情况与预测内容相匹配时，才会记为T；反之即为F。
也就是说，T 和 F 并不是标记实际情况中事件是否发生，而是表示实际情况与预测内容是否一致。
由混淆矩阵派生的关键指标 在实践中，混淆矩阵中的TP、FN、FP、TN通常是记录测试模型时，符合对应情况的测试样本数量。
比如说我们训练好了模型，测试时我们输入了1000个样本，结果分别为：
400个样本被预测为会发生异常事件
其中150个样本真的发生了异常事件，250个样本没有发生异常事件 600个样本被预测为不发生异常事件
其中50个样本真的发生了异常事件，550个样本没有发生异常事件 此时，这个模型的混淆矩阵可以记为：">
  <meta property="og:locale" content="zh-cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2026-02-04T19:22:30+08:00">
    <meta property="article:modified_time" content="2026-02-04T19:22:30+08:00">
      <meta property="og:image" content="https://clarkflybee.github.io/images/show.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://clarkflybee.github.io/images/show.png">
<meta name="twitter:title" content="混淆矩阵与 AUC：理解T/F/P/N分类评估指标">
<meta name="twitter:description" content="
最近参与的医学场景的项目中，模型的评价指标之一是AUC。
要讲清楚这个指标，需要首先了解一个评价模型的经典工具：混淆矩阵。

混淆矩阵 —— 模型能不能“明辨是非”
基础定义
我们训练AI模型，一个典型的任务是去预测一个事情是否会发生。
那医学场景举个例子：


我们给模型输入过去手术的数据，让它学习其中的特征。


我们的目的是希望训练后的模型在接受一段时间的手术数据输入后，给出未来一定时间内发生某类异常事件的可能性。


那么如何评价这个模型做的好不好呢？简单来说，需要记录预测结果与实际情况是否一致。我们定义：


预测结果


预测为正例（Positive, P）


预测为负例（Negative, N）




实际情况


实际为正例


实际为负例




对于这四种情况排列组合，我们就会得到一个模型的混淆矩阵（Confusion Matrix）：

  
      
          
          预测为正例 P
          预测为负例 N
      
  
  
      
          实际为正例
          TP（True Positive）
          FN（False Negative）
      
      
          实际为负例
          FP（False Positive）
          TN（True Negative）
      
  

对于矩阵的四个象限，其含义分别为：

  
      
          缩写
          含义
          场景
      
  
  
      
          TP
          预测为正，实际为正
          ✅ 正确识别阳性（如：有异常事件有警报）
      
      
          TN
          预测为负，实际为负
          ✅ 正确识别阴性（如：无异常事件无警报）
      
      
          FP
          预测为正，实际为负
          ❌ 误报（如：无异常事件有警报）
      
      
          FN
          预测为负，实际为正
          ❌ 漏报（如：有异常事件无警报）
      
  


这里我经常搞糊涂，Positive和Negative分别对应的是预测的情况。预测为正例，指预测内容为事件发生，在混淆矩阵中标记为P，反之为N。
但与预测情况相对的，实际情况为正例，并不意味着对应情况记作T。
事实上，当实际情况与预测内容相匹配时，才会记为T；反之即为F。
也就是说，T 和 F 并不是标记实际情况中事件是否发生，而是表示实际情况与预测内容是否一致。

由混淆矩阵派生的关键指标
在实践中，混淆矩阵中的TP、FN、FP、TN通常是记录测试模型时，符合对应情况的测试样本数量。
比如说我们训练好了模型，测试时我们输入了1000个样本，结果分别为：


400个样本被预测为会发生异常事件

其中150个样本真的发生了异常事件，250个样本没有发生异常事件



600个样本被预测为不发生异常事件

其中50个样本真的发生了异常事件，550个样本没有发生异常事件



此时，这个模型的混淆矩阵可以记为：">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "文章",
      "item": "https://clarkflybee.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "混淆矩阵与 AUC：理解T/F/P/N分类评估指标",
      "item": "https://clarkflybee.github.io/posts/2026-02-04-auc-confusion-matrix-primer/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "混淆矩阵与 AUC：理解T/F/P/N分类评估指标",
  "name": "混淆矩阵与 AUC：理解T\/F\/P\/N分类评估指标",
  "description": " 最近参与的医学场景的项目中，模型的评价指标之一是AUC。\n要讲清楚这个指标，需要首先了解一个评价模型的经典工具：混淆矩阵。\n混淆矩阵 —— 模型能不能“明辨是非” 基础定义 我们训练AI模型，一个典型的任务是去预测一个事情是否会发生。\n那医学场景举个例子：\n我们给模型输入过去手术的数据，让它学习其中的特征。\n我们的目的是希望训练后的模型在接受一段时间的手术数据输入后，给出未来一定时间内发生某类异常事件的可能性。\n那么如何评价这个模型做的好不好呢？简单来说，需要记录预测结果与实际情况是否一致。我们定义：\n预测结果\n预测为正例（Positive, P）\n预测为负例（Negative, N）\n实际情况\n实际为正例\n实际为负例\n对于这四种情况排列组合，我们就会得到一个模型的混淆矩阵（Confusion Matrix）：\n预测为正例 P 预测为负例 N 实际为正例 TP（True Positive） FN（False Negative） 实际为负例 FP（False Positive） TN（True Negative） 对于矩阵的四个象限，其含义分别为：\n缩写 含义 场景 TP 预测为正，实际为正 ✅ 正确识别阳性（如：有异常事件有警报） TN 预测为负，实际为负 ✅ 正确识别阴性（如：无异常事件无警报） FP 预测为正，实际为负 ❌ 误报（如：无异常事件有警报） FN 预测为负，实际为正 ❌ 漏报（如：有异常事件无警报） 这里我经常搞糊涂，Positive和Negative分别对应的是预测的情况。预测为正例，指预测内容为事件发生，在混淆矩阵中标记为P，反之为N。\n但与预测情况相对的，实际情况为正例，并不意味着对应情况记作T。\n事实上，当实际情况与预测内容相匹配时，才会记为T；反之即为F。\n也就是说，T 和 F 并不是标记实际情况中事件是否发生，而是表示实际情况与预测内容是否一致。\n由混淆矩阵派生的关键指标 在实践中，混淆矩阵中的TP、FN、FP、TN通常是记录测试模型时，符合对应情况的测试样本数量。\n比如说我们训练好了模型，测试时我们输入了1000个样本，结果分别为：\n400个样本被预测为会发生异常事件\n其中150个样本真的发生了异常事件，250个样本没有发生异常事件 600个样本被预测为不发生异常事件\n其中50个样本真的发生了异常事件，550个样本没有发生异常事件 此时，这个模型的混淆矩阵可以记为：\n",
  "keywords": [
    
  ],
  "articleBody": " 最近参与的医学场景的项目中，模型的评价指标之一是AUC。\n要讲清楚这个指标，需要首先了解一个评价模型的经典工具：混淆矩阵。\n混淆矩阵 —— 模型能不能“明辨是非” 基础定义 我们训练AI模型，一个典型的任务是去预测一个事情是否会发生。\n那医学场景举个例子：\n我们给模型输入过去手术的数据，让它学习其中的特征。\n我们的目的是希望训练后的模型在接受一段时间的手术数据输入后，给出未来一定时间内发生某类异常事件的可能性。\n那么如何评价这个模型做的好不好呢？简单来说，需要记录预测结果与实际情况是否一致。我们定义：\n预测结果\n预测为正例（Positive, P）\n预测为负例（Negative, N）\n实际情况\n实际为正例\n实际为负例\n对于这四种情况排列组合，我们就会得到一个模型的混淆矩阵（Confusion Matrix）：\n预测为正例 P 预测为负例 N 实际为正例 TP（True Positive） FN（False Negative） 实际为负例 FP（False Positive） TN（True Negative） 对于矩阵的四个象限，其含义分别为：\n缩写 含义 场景 TP 预测为正，实际为正 ✅ 正确识别阳性（如：有异常事件有警报） TN 预测为负，实际为负 ✅ 正确识别阴性（如：无异常事件无警报） FP 预测为正，实际为负 ❌ 误报（如：无异常事件有警报） FN 预测为负，实际为正 ❌ 漏报（如：有异常事件无警报） 这里我经常搞糊涂，Positive和Negative分别对应的是预测的情况。预测为正例，指预测内容为事件发生，在混淆矩阵中标记为P，反之为N。\n但与预测情况相对的，实际情况为正例，并不意味着对应情况记作T。\n事实上，当实际情况与预测内容相匹配时，才会记为T；反之即为F。\n也就是说，T 和 F 并不是标记实际情况中事件是否发生，而是表示实际情况与预测内容是否一致。\n由混淆矩阵派生的关键指标 在实践中，混淆矩阵中的TP、FN、FP、TN通常是记录测试模型时，符合对应情况的测试样本数量。\n比如说我们训练好了模型，测试时我们输入了1000个样本，结果分别为：\n400个样本被预测为会发生异常事件\n其中150个样本真的发生了异常事件，250个样本没有发生异常事件 600个样本被预测为不发生异常事件\n其中50个样本真的发生了异常事件，550个样本没有发生异常事件 此时，这个模型的混淆矩阵可以记为：\n预测为正例 P 预测为负例 N 总计 实际为正例 TP=150 FN=50 200 实际为负例 FP=250 TN=550 800 总计 400 600 1000 那么针对这些数据，我们设计了许多指标来量化模型的质量：\n准确率（Accuracy） $$ \\frac{TP+TN}{TP+TN+FP+FN} $$\n这个指标描述了所有样本中，模型预测正确的比例。\n这是最直接的衡量模型的指标，可以对模型的整体性能做一个快速评估。\n计算可得，上面模型的准确率为：$\\frac{150+550}{1000}=0.7$\n但这并不是完美的指标，当类别不平衡时会严重失真\n比如说，1000个样本中，实际发生异常事件的只有10个（1%），无异常事件的有990个（99%），这是一种极端的事件分布，异常事件的出现概率很小。\n此时，如果有一个”傻瓜“模型，它对所有样本都预测无异常事件。这时的Accuracy达到了惊人的99%。但这明显是没有意义的，模型实际上没有完成我们希望的任务。\n精确率（Precision） $$ \\frac{TP}{TP+FP} $$\n这个指标描述的是，模型预测为正的样本中，有多少是真正为正的，因此也叫查准率。\n对于一个高精确率的模型，意味着它的误报（FP）少，模型预测说会发生异常，那么大概率会发生异常。\n反之，一个低精确率的模型则是经常搞”狼来了“，明明没有异常，却说有异常，这显然是不好的。\n计算得到精确率为：$\\frac{150}{150+250}=0.375$\n召回率（Recall） $$ \\frac{TP}{TP+FN} $$\n这个指标描述了，实际为正的样本中，模型正确预测出来的样本占的比例，也叫查全率、灵敏度\n一个高召回率的模型，意味着它的漏报（FN）少，模型能够捕捉到几乎所有的异常事件。\n反之，则说明模型会有盲区，一部分异常事件会捕捉不到。\n计算得到召回率为：$\\frac{150}{150+50}=0.75$\nF1-Score $$ 2 \\times \\frac{Precision \\times Recall}{Precision + Recall} $$\n这是精确率和召回率的调和平均，综合衡量模型性能。\n调和平均：对低值更敏感，强制要求两者都高\n以防你忘记什么是调和平均：\n$$ \\frac{2}{\\frac{1}{a}+\\frac{1}{b}}=\\frac{2ab}{a+b} $$\n算术平均：会被高值主导，比如说精确率和召回率分别为100%与0%（极端一些，实际不会出现这种情况），算术平均为50%，但模型明显是不可用的。\nF1-Score 避免了选择Precision和Recall的权衡困扰，因此比较模型时，用 F1-Score 是个好选择。\n计算可得：$F1=2 \\times \\frac{0.375 \\times 0,75}{0.375+0.75}=0.5$\nROC——不同阈值下模型的权衡能力 ROC（Receiver Operating Characteristic，接收者操作特征曲线），它是评估二分类模型的核心工具之一。\n在解释ROC之前，我们先来聊聊模型分类的阈值。还是回到医学场景，我们的模型一般直接输出的是0~1之间的小数，表示当前样本中可能发生异常事件的概率值。\n问题来了，概率值是多少时，我们认为这个会发生异常事件呢？\n也就是说，我们需要给定一个阈值。当概率值\u003e阈值时，预测为正例；反之，预测为负例。\n这意味着，一个模型中预测正负例分别的数量会与阈值息息相关，我们取不同的阈值，可以计算出不同的TP、FP、TN、FN，进而计算不同的指标。\n借助这一点，我们可以通过绘制ROC图来描述不同阈值下模型的能力。\nX轴：假正率 FPR = FP/(FP+TN)，实际为负例的样本中模型预测为正的比例\nY轴：真正率 TPR = TP/(TP+FN) = Recall，实际为正例的样本中模型预测为正的比例\n对于一个模型测试的数据，我们取不同的阈值，可以分别算出多个 (FPR, TPR)，作为横纵坐标的位置，画在图中并连线，就得到了ROC图\n根据前面的定义，我们可以得到ROC的一些特征：\nROC图横纵坐标都局限在 [0, 1] 上\n阈值定的很低时，模型不管怎么输出，都被认为预测为正例，此时横纵坐标均为1，(1, 1)\n阈值定的很高时，模型不管怎么数据，都被认为预测为负例，此时横纵坐标均为0，(0, 0)\n图中有一条直线，表示随机猜测（Random Classifier），顾名思义，就是模型随机输出预测概率，那么预测正确与错误的概率应该是相同的，ROC图就是一条y=x的直线。\n一般来说，一个训练好的模型一般是在这条直线上方的，越远离这条线，说明模型性能越好，反之越差。\n最理想的状态，我们希望模型假正率为 0% 的同时，预测正确的概率为 100% 。\nROC图足够直观，我们从其中提取出了一个量化指标：AUC值\nAUC 定义 简单来说，AUC就是ROC曲线下的面积，取值为 [0,1]。\n可以发现，AUC值的大小不依赖于特定的阈值，适合评估模型整体性能，且对类别不平衡的情况不敏感。\nAUC值方便对比模型之间的性能，我参与的医学场景项目中，AUC就是衡量我们模型性能的一个重要指标。\nAUC的概率解释 AUC的值可以理解为一个概率：\n随机抽取一个正样本与一个负样本，模型给正样本打的分高于负样本的概率\n（“打分”指的就是样本输入模型后，模型输出的值，即模型预测当前样本为真的概率）\n我们来根据实际数据理解一下：\nAUC 意味着 实际体验 1.0 正样本的分数永远排在负样本前面 随便设个阈值都能完美分离 0.9 90% 的正样本分数更高 偶尔有\"难例\"混淆，但总体可靠 0.7 70% 的正样本分数更高 正负有相当重叠，需要谨慎选阈值 0.5 和随机猜一样 模型完全没学到特征，在它眼中正负样本没有区别 局限性 AUC并不反映精确率，或者说查准率。我们可以结合 PR曲线。\n下面通过一个案例来具体说明ROC图的应用：\n案例：垃圾邮件识别 我们规定：\n正例（1）：认为是垃圾邮件\n负例（0）：认为是正常邮件\n现在我们创建1000条模拟数据如下：\n类别 数量 模型预测概率分布 垃圾邮件（正例） 100 封 90封高概率(0.8-0.95)，10封低概率(0.1-0.3) 正常邮件（负例） 900 封 50封高概率(0.6-0.75)，850封低概率(0.05-0.2) 下面是在一种可能的分布下，不同阈值对应的混淆矩阵：\n阈值 预测规则 TP FP TN FN TPR FPR Precision 0.9 极严格 60 5 895 40 60% 0.6% 92.3% 0.7 严格 80 15 885 20 80% 1.7% 84.2% 0.5 平衡 90 35 865 10 90% 3.9% 72.0% 0.3 宽松 95 80 820 5 95% 8.9% 54.3% 0.1 极宽松 99 200 700 1 99% 22.2% 33.1% 我们可以对此画一个ROC图并计算AUC值：\n画图和模拟数据的代码见下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 # generate_fraud_roc.py import matplotlib.pyplot as plt import numpy as np from sklearn.metrics import roc_curve, auc plt.rcParams['font.family'] = 'SimHei' # Windows 示例 plt.rcParams['axes.unicode_minus'] = False # 解决负号显示问题 # 构造数据 np.random.seed(42) # 100个垃圾邮件：90个高概率，10个低概率 fraud_scores = np.concatenate([ np.random.uniform(0.8, 0.95, 90), np.random.uniform(0.1, 0.3, 10) ]) # 900个正常邮件：50个高概率（误判），850个低概率 normal_scores = np.concatenate([ np.random.uniform(0.6, 0.75, 50), # 难以区分的正常邮件 np.random.uniform(0.05, 0.2, 850) ]) y_true = np.array([1]*100 + [0]*900) y_score = np.concatenate([fraud_scores, normal_scores]) # 计算 ROC fpr, tpr, thresholds = roc_curve(y_true, y_score) roc_auc = auc(fpr, tpr) # 绘图 fig, ax = plt.subplots(figsize=(5, 4), dpi=150) # ROC 曲线 ax.plot(fpr, tpr, color='#e63946', linewidth=3, label=f'垃圾模型检测模型 (AUC = {roc_auc:.3f})') # 对角线（随机猜测） ax.plot([0, 1], [0, 1], color='#adb5bd', linewidth=2, linestyle='--', label='随机猜测 (AUC = 0.500)') # 样式 ax.set_xlim([-0.02, 1.0]) ax.set_ylim([0.0, 1.02]) ax.set_xlabel('FPR = FP / (FP + TN)', fontsize=12) ax.set_ylabel('TPR = TP / (TP + FN)', fontsize=12) ax.set_title('ROC', fontsize=14, fontweight='bold', pad=20) ax.legend(loc='lower right', fontsize=10, framealpha=0.9) ax.grid(True, alpha=0.3, linestyle='--') plt.tight_layout() plt.savefig('roc_fraud_detection.png', dpi=150, bbox_inches='tight', facecolor='white') print(f\"✅ AUC = {roc_auc:.3f}\") print(\"✅ ROC图已保存: roc_fraud_detection.png\") plt.show() 参考 【ROC曲线】ROC曲线易懂理解与多分类的理解-CSDN博客\n",
  "wordCount" : "499",
  "inLanguage": "zh-cn",
  "image": "https://clarkflybee.github.io/images/show.png","datePublished": "2026-02-04T19:22:30+08:00",
  "dateModified": "2026-02-04T19:22:30+08:00",
  "author":{
    "@type": "Person",
    "name": "ClarkFlyBee"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://clarkflybee.github.io/posts/2026-02-04-auc-confusion-matrix-primer/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "ClarkFlyBee's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://clarkflybee.github.io/favicon.ico"
    }
  }
}
</script>
</head>
<body id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://clarkflybee.github.io/" accesskey="h" title="ClarkFlyBee&#39;s Blog (Alt + H)">ClarkFlyBee&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://clarkflybee.github.io/" title="首页">
                    <span>首页</span>
                </a>
            </li>
            <li>
                <a href="https://clarkflybee.github.io/posts/" title="文章">
                    <span>文章</span>
                </a>
            </li>
            <li>
                <a href="https://clarkflybee.github.io/about/" title="关于">
                    <span>关于</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      混淆矩阵与 AUC：理解T/F/P/N分类评估指标
    </h1>
    <div class="post-meta"><span title='2026-02-04 19:22:30 +0800 CST'>February 4, 2026</span>&nbsp;·&nbsp;<span>ClarkFlyBee</span>

</div>
  </header> 
  <div class="post-content"><blockquote>
<p>最近参与的医学场景的项目中，模型的评价指标之一是AUC。</p>
<p>要讲清楚这个指标，需要首先了解一个评价模型的经典工具：混淆矩阵。</p>
</blockquote>
<h2 id="混淆矩阵--模型能不能明辨是非">混淆矩阵 —— 模型能不能“明辨是非”<a hidden class="anchor" aria-hidden="true" href="#混淆矩阵--模型能不能明辨是非">#</a></h2>
<h3 id="基础定义">基础定义<a hidden class="anchor" aria-hidden="true" href="#基础定义">#</a></h3>
<p>我们训练AI模型，一个典型的任务是去预测一个事情是否会发生。</p>
<p>那医学场景举个例子：</p>
<ul>
<li>
<p>我们给模型输入过去手术的数据，让它学习其中的特征。</p>
</li>
<li>
<p>我们的目的是希望训练后的模型在接受一段时间的手术数据输入后，给出未来一定时间内发生某类异常事件的<strong>可能性</strong>。</p>
</li>
</ul>
<p>那么如何评价这个模型做的好不好呢？简单来说，需要记录预测结果与实际情况是否一致。我们定义：</p>
<ul>
<li>
<p>预测结果</p>
<ol>
<li>
<p>预测为正例（Positive, <strong>P</strong>）</p>
</li>
<li>
<p>预测为负例（Negative, <strong>N</strong>）</p>
</li>
</ol>
</li>
<li>
<p>实际情况</p>
<ol>
<li>
<p>实际为正例</p>
</li>
<li>
<p>实际为负例</p>
</li>
</ol>
</li>
</ul>
<p>对于这四种情况排列组合，我们就会得到一个模型的<strong>混淆矩阵</strong>（<em><strong>Confusion Matrix</strong></em>）：</p>
<table>
  <thead>
      <tr>
          <th></th>
          <th>预测为正例 <strong>P</strong></th>
          <th>预测为负例 <strong>N</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>实际为正例</td>
          <td>TP（True Positive）</td>
          <td>FN（False Negative）</td>
      </tr>
      <tr>
          <td>实际为负例</td>
          <td>FP（False Positive）</td>
          <td>TN（True Negative）</td>
      </tr>
  </tbody>
</table>
<p>对于矩阵的四个象限，其含义分别为：</p>
<table>
  <thead>
      <tr>
          <th>缩写</th>
          <th>含义</th>
          <th>场景</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>TP</td>
          <td>预测为正，实际为正</td>
          <td>✅ 正确识别阳性（如：有异常事件有警报）</td>
      </tr>
      <tr>
          <td>TN</td>
          <td>预测为负，实际为负</td>
          <td>✅ 正确识别阴性（如：无异常事件无警报）</td>
      </tr>
      <tr>
          <td>FP</td>
          <td>预测为正，实际为负</td>
          <td>❌ 误报（如：无异常事件有警报）</td>
      </tr>
      <tr>
          <td>FN</td>
          <td>预测为负，实际为正</td>
          <td>❌ 漏报（如：有异常事件无警报）</td>
      </tr>
  </tbody>
</table>
<blockquote>
<p>这里我经常搞糊涂，<strong>P</strong>ositive和<strong>N</strong>egative分别对应的是预测的情况。预测为正例，指预测内容为事件发生，在混淆矩阵中标记为<strong>P</strong>，反之为<strong>N</strong>。</p>
<p>但与预测情况相对的，实际情况为正例，并不意味着对应情况记作T。</p>
<p>事实上，当实际情况与预测内容相匹配时，才会记为<strong>T</strong>；反之即为<strong>F</strong>。</p>
<p>也就是说，<strong>T</strong> 和 <strong>F</strong> 并不是标记<strong>实际情况</strong>中事件是否发生，而是表示实际情况与预测内容<strong>是否一致</strong>。</p>
</blockquote>
<h3 id="由混淆矩阵派生的关键指标">由混淆矩阵派生的关键指标<a hidden class="anchor" aria-hidden="true" href="#由混淆矩阵派生的关键指标">#</a></h3>
<p>在实践中，混淆矩阵中的TP、FN、FP、TN通常是记录测试模型时，符合对应情况的测试样本数量。</p>
<p>比如说我们训练好了模型，测试时我们输入了1000个样本，结果分别为：</p>
<ul>
<li>
<p>400个样本被<strong>预测为会发生</strong>异常事件</p>
<ul>
<li>其中150个样本<strong>真的发生</strong>了异常事件，250个样本<strong>没有发生</strong>异常事件</li>
</ul>
</li>
<li>
<p>600个样本被<strong>预测为不发生</strong>异常事件</p>
<ul>
<li>其中50个样本<strong>真的发生</strong>了异常事件，550个样本<strong>没有发生</strong>异常事件</li>
</ul>
</li>
</ul>
<p>此时，这个模型的混淆矩阵可以记为：</p>
<table>
  <thead>
      <tr>
          <th></th>
          <th>预测为正例 <strong>P</strong></th>
          <th>预测为负例 <strong>N</strong></th>
          <th>总计</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>实际为正例</td>
          <td>TP=150</td>
          <td>FN=50</td>
          <td>200</td>
      </tr>
      <tr>
          <td>实际为负例</td>
          <td>FP=250</td>
          <td>TN=550</td>
          <td>800</td>
      </tr>
      <tr>
          <td>总计</td>
          <td>400</td>
          <td>600</td>
          <td>1000</td>
      </tr>
  </tbody>
</table>
<p>那么针对这些数据，我们设计了许多指标来量化模型的质量：</p>
<h4 id="准确率accuracy">准确率（<em>Accuracy</em>）<a hidden class="anchor" aria-hidden="true" href="#准确率accuracy">#</a></h4>
<p>$$
\frac{TP+TN}{TP+TN+FP+FN}
$$</p>
<p>这个指标描述了<strong>所有样本</strong>中，模型<strong>预测正确</strong>的比例。</p>
<p>这是最直接的衡量模型的指标，可以对模型的整体性能做一个快速评估。</p>
<p>计算可得，上面模型的准确率为：$\frac{150+550}{1000}=0.7$</p>
<p>但这并不是完美的指标，当<strong>类别不平衡</strong>时会<strong>严重失真</strong></p>
<blockquote>
<p>比如说，1000个样本中，实际发生异常事件的只有10个（1%），无异常事件的有990个（99%），这是一种极端的事件分布，异常事件的出现概率很小。</p>
<p>此时，如果有一个”傻瓜“模型，它对所有样本都预测无异常事件。这时的Accuracy达到了惊人的99%。但这明显是没有意义的，模型实际上没有完成我们希望的任务。</p>
</blockquote>
<h4 id="精确率precision">精确率（<em>Precision</em>）<a hidden class="anchor" aria-hidden="true" href="#精确率precision">#</a></h4>
<p>$$
\frac{TP}{TP+FP}
$$</p>
<p>这个指标描述的是，模型<strong>预测为正</strong>的样本中，有多少是<strong>真正为正</strong>的，因此也叫<strong>查准率</strong>。</p>
<p>对于一个高精确率的模型，意味着它的<strong>误报（FP）少</strong>，模型预测说会发生异常，那么大概率会发生异常。</p>
<p>反之，一个低精确率的模型则是经常搞”狼来了“，明明没有异常，却说有异常，这显然是不好的。</p>
<p>计算得到精确率为：$\frac{150}{150+250}=0.375$</p>
<h4 id="召回率recall">召回率（<em>Recall</em>）<a hidden class="anchor" aria-hidden="true" href="#召回率recall">#</a></h4>
<p>$$
\frac{TP}{TP+FN}
$$</p>
<p>这个指标描述了，<strong>实际为正</strong>的样本中，模型<strong>正确预测</strong>出来的样本占的比例，也叫<strong>查全率</strong>、<strong>灵敏度</strong></p>
<p>一个高召回率的模型，意味着它的<strong>漏报（FN）少</strong>，模型能够捕捉到几乎所有的异常事件。</p>
<p>反之，则说明模型会有盲区，一部分异常事件会捕捉不到。</p>
<p>计算得到召回率为：$\frac{150}{150+50}=0.75$</p>
<h4 id="f1-score"><em>F1-Score</em><a hidden class="anchor" aria-hidden="true" href="#f1-score">#</a></h4>
<p>$$
2 \times \frac{Precision \times Recall}{Precision + Recall}
$$</p>
<p>这是精确率和召回率的<strong>调和平均</strong>，综合衡量模型性能。</p>
<blockquote>
<ul>
<li>
<p>调和平均：对低值更敏感，强制要求两者都高</p>
<blockquote>
<p>以防你忘记什么是调和平均：</p>
<p>$$
\frac{2}{\frac{1}{a}+\frac{1}{b}}=\frac{2ab}{a+b}
$$</p>
</blockquote>
</li>
<li>
<p>算术平均：会被高值主导，比如说精确率和召回率分别为100%与0%（极端一些，实际不会出现这种情况），算术平均为50%，但模型明显是不可用的。</p>
</li>
</ul>
</blockquote>
<p>F1-Score 避免了选择Precision和Recall的权衡困扰，因此比较模型时，用 F1-Score 是个好选择。</p>
<p>计算可得：$F1=2 \times \frac{0.375 \times 0,75}{0.375+0.75}=0.5$</p>
<h2 id="roc不同阈值下模型的权衡能力">ROC——不同阈值下模型的权衡能力<a hidden class="anchor" aria-hidden="true" href="#roc不同阈值下模型的权衡能力">#</a></h2>
<p>ROC（Receiver Operating Characteristic，接收者操作特征曲线），它是评估二分类模型的核心工具之一。</p>
<p>在解释ROC之前，我们先来聊聊模型分类的阈值。还是回到医学场景，我们的模型一般直接输出的是0~1之间的小数，表示当前样本中可能发生异常事件的<strong>概率值</strong>。</p>
<blockquote>
<p>问题来了，概率值是多少时，我们认为这个会发生异常事件呢？</p>
</blockquote>
<p>也就是说，我们需要给定一个<strong>阈值</strong>。当概率值&gt;阈值时，预测为正例；反之，预测为负例。</p>
<p>这意味着，一个模型中预测正负例分别的数量会与阈值息息相关，我们取不同的阈值，可以计算出不同的TP、FP、TN、FN，进而计算不同的指标。</p>
<p>借助这一点，我们可以通过绘制ROC图来描述不同阈值下模型的能力。</p>
<ul>
<li>
<p>X轴：假正率 FPR = FP/(FP+TN)，<strong>实际为负例</strong>的样本中模型<strong>预测为正</strong>的比例</p>
</li>
<li>
<p>Y轴：真正率 TPR = TP/(TP+FN) = Recall，<strong>实际为正例</strong>的样本中模型<strong>预测为正</strong>的比例</p>
</li>
<li>
<p>对于一个模型测试的数据，我们取不同的阈值，可以分别算出多个 (FPR, TPR)，作为横纵坐标的位置，画在图中并连线，就得到了ROC图</p>
</li>
</ul>
<p><img alt="ROC图（示例）" loading="lazy" src="/posts/2026-02-04-auc-confusion-matrix-primer/roc.png"></p>
<p>根据前面的定义，我们可以得到ROC的一些特征：</p>
<ul>
<li>
<p>ROC图横纵坐标都局限在 [0, 1] 上</p>
</li>
<li>
<p>阈值定的很低时，模型不管怎么输出，都被认为预测为正例，此时横纵坐标均为1，(1, 1)</p>
</li>
<li>
<p>阈值定的很高时，模型不管怎么数据，都被认为预测为负例，此时横纵坐标均为0，(0, 0)</p>
</li>
</ul>
<p>图中有一条直线，表示随机猜测（Random Classifier），顾名思义，就是模型随机输出预测概率，那么预测正确与错误的概率应该是相同的，ROC图就是一条y=x的直线。</p>
<p>一般来说，一个训练好的模型一般是在这条直线上方的，越远离这条线，说明模型性能越好，反之越差。</p>
<p>最理想的状态，我们希望模型假正率为 <strong>0%</strong> 的同时，预测正确的概率为 <strong>100%</strong> 。</p>
<p>ROC图足够直观，我们从其中提取出了一个量化指标：AUC值</p>
<h3 id="auc">AUC<a hidden class="anchor" aria-hidden="true" href="#auc">#</a></h3>
<h4 id="定义">定义<a hidden class="anchor" aria-hidden="true" href="#定义">#</a></h4>
<p>简单来说，AUC就是<strong>ROC曲线下的面积</strong>，取值为 [0,1]。</p>
<p>可以发现，AUC值的大小<strong>不依赖于特定的阈值</strong>，适合评估模型整体性能，且对类别不平衡的情况不敏感。</p>
<blockquote>
<p>AUC值方便对比模型之间的性能，我参与的医学场景项目中，AUC就是衡量我们<strong>模型性能</strong>的一个重要指标。</p>
</blockquote>
<h4 id="auc的概率解释">AUC的概率解释<a hidden class="anchor" aria-hidden="true" href="#auc的概率解释">#</a></h4>
<p>AUC的值可以理解为一个概率：</p>
<blockquote>
<p>随机抽取一个正样本与一个负样本，模型给正样本打的分<strong>高于</strong>负样本的概率</p>
<p>（“打分”指的就是样本输入模型后，模型输出的值，即模型预测当前样本为真的概率）</p>
</blockquote>
<p>我们来根据实际数据理解一下：</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">AUC</th>
          <th style="text-align: left">意味着</th>
          <th style="text-align: left">实际体验</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">1.0</td>
          <td style="text-align: left">正样本的分数永远排在负样本前面</td>
          <td style="text-align: left">随便设个阈值都能完美分离</td>
      </tr>
      <tr>
          <td style="text-align: left">0.9</td>
          <td style="text-align: left">90% 的正样本分数更高</td>
          <td style="text-align: left">偶尔有&quot;难例&quot;混淆，但总体可靠</td>
      </tr>
      <tr>
          <td style="text-align: left">0.7</td>
          <td style="text-align: left">70% 的正样本分数更高</td>
          <td style="text-align: left">正负有相当重叠，需要谨慎选阈值</td>
      </tr>
      <tr>
          <td style="text-align: left">0.5</td>
          <td style="text-align: left">和随机猜一样</td>
          <td style="text-align: left">模型完全没学到特征，在它眼中正负样本没有区别</td>
      </tr>
  </tbody>
</table>
<h4 id="局限性">局限性<a hidden class="anchor" aria-hidden="true" href="#局限性">#</a></h4>
<p>AUC并不反映精确率，或者说查准率。我们可以结合 <em><strong>PR曲线</strong></em>。</p>
<hr>
<p>下面通过一个案例来具体说明ROC图的应用：</p>
<h3 id="案例垃圾邮件识别">案例：垃圾邮件识别<a hidden class="anchor" aria-hidden="true" href="#案例垃圾邮件识别">#</a></h3>
<p>我们规定：</p>
<ul>
<li>
<p>正例（1）：认为是垃圾邮件</p>
</li>
<li>
<p>负例（0）：认为是正常邮件</p>
</li>
</ul>
<p>现在我们创建1000条模拟数据如下：</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">类别</th>
          <th>数量</th>
          <th style="text-align: left">模型预测概率分布</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">垃圾邮件（正例）</td>
          <td>100 封</td>
          <td style="text-align: left">90封高概率(0.8-0.95)，10封低概率(0.1-0.3)</td>
      </tr>
      <tr>
          <td style="text-align: left">正常邮件（负例）</td>
          <td>900 封</td>
          <td style="text-align: left">50封高概率(0.6-0.75)，850封低概率(0.05-0.2)</td>
      </tr>
  </tbody>
</table>
<p>下面是在一种可能的分布下，不同阈值对应的混淆矩阵：</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">阈值</th>
          <th style="text-align: left">预测规则</th>
          <th style="text-align: center">TP</th>
          <th style="text-align: center">FP</th>
          <th style="text-align: center">TN</th>
          <th style="text-align: center">FN</th>
          <th style="text-align: center">TPR</th>
          <th style="text-align: center">FPR</th>
          <th>Precision</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left"><strong>0.9</strong></td>
          <td style="text-align: left">极严格</td>
          <td style="text-align: center">60</td>
          <td style="text-align: center">5</td>
          <td style="text-align: center">895</td>
          <td style="text-align: center">40</td>
          <td style="text-align: center">60%</td>
          <td style="text-align: center">0.6%</td>
          <td>92.3%</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>0.7</strong></td>
          <td style="text-align: left">严格</td>
          <td style="text-align: center">80</td>
          <td style="text-align: center">15</td>
          <td style="text-align: center">885</td>
          <td style="text-align: center">20</td>
          <td style="text-align: center">80%</td>
          <td style="text-align: center">1.7%</td>
          <td>84.2%</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>0.5</strong></td>
          <td style="text-align: left">平衡</td>
          <td style="text-align: center">90</td>
          <td style="text-align: center">35</td>
          <td style="text-align: center">865</td>
          <td style="text-align: center">10</td>
          <td style="text-align: center"><strong>90%</strong></td>
          <td style="text-align: center"><strong>3.9%</strong></td>
          <td>72.0%</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>0.3</strong></td>
          <td style="text-align: left">宽松</td>
          <td style="text-align: center">95</td>
          <td style="text-align: center">80</td>
          <td style="text-align: center">820</td>
          <td style="text-align: center">5</td>
          <td style="text-align: center">95%</td>
          <td style="text-align: center">8.9%</td>
          <td>54.3%</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>0.1</strong></td>
          <td style="text-align: left">极宽松</td>
          <td style="text-align: center">99</td>
          <td style="text-align: center">200</td>
          <td style="text-align: center">700</td>
          <td style="text-align: center">1</td>
          <td style="text-align: center">99%</td>
          <td style="text-align: center">22.2%</td>
          <td>33.1%</td>
      </tr>
  </tbody>
</table>
<p>我们可以对此画一个ROC图并计算AUC值：</p>
<p><img alt="ROC（垃圾邮件案例）" loading="lazy" src="/posts/2026-02-04-auc-confusion-matrix-primer/roc_fraud_detection.png"></p>
<p>画图和模拟数据的代码见下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># generate_fraud_roc.py</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;SimHei&#39;</span> <span class="c1"># Windows 示例</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.unicode_minus&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># 解决负号显示问题</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 构造数据</span>
</span></span><span class="line"><span class="cl"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 100个垃圾邮件：90个高概率，10个低概率</span>
</span></span><span class="line"><span class="cl"><span class="n">fraud_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mi">90</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 900个正常邮件：50个高概率（误判），850个低概率</span>
</span></span><span class="line"><span class="cl"><span class="n">normal_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>  <span class="c1"># 难以区分的正常邮件</span>
</span></span><span class="line"><span class="cl">    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">850</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">900</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">y_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fraud_scores</span><span class="p">,</span> <span class="n">normal_scores</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 计算 ROC</span>
</span></span><span class="line"><span class="cl"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 绘图</span>
</span></span><span class="line"><span class="cl"><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ROC 曲线</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#e63946&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;垃圾模型检测模型 (AUC = </span><span class="si">{</span><span class="n">roc_auc</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 对角线（随机猜测）</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#adb5bd&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;随机猜测 (AUC = 0.500)&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 样式</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.02</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;FPR = FP / (FP + TN)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;TPR = TP / (TP + FN)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;ROC&#39;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">             <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">framealpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;roc_fraud_detection.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;✅ AUC = </span><span class="si">{</span><span class="n">roc_auc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;✅ ROC图已保存: roc_fraud_detection.png&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="参考">参考<a hidden class="anchor" aria-hidden="true" href="#参考">#</a></h2>
<p><a href="https://blog.csdn.net/qq_45047062/article/details/137808696">【ROC曲线】ROC曲线易懂理解与多分类的理解-CSDN博客</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="next" href="https://clarkflybee.github.io/posts/first-blog/">
    <span class="title">下一页 »</span>
    <br>
    <span>第一篇博客</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>© 2026 ClarkFlyBee · <a href="https://github.com/clarkflybee">GitHub</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
